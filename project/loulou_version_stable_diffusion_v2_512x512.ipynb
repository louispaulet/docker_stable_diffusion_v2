{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKVPm8Fo9Zh7"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import vmap\n",
    "x = torch.randn(3)\n",
    "y = vmap(torch.sin)(x)\n",
    "assert torch.allclose(y, x.sin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functorch\n",
    "!python -m xformers.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAN5CI5-BlXp"
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "from torch import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = EulerDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-2-base\", subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote model path\n",
    "# model_id = \"stabilityai/stable-diffusion-2-base\"\n",
    "\n",
    "# local model path\n",
    "model_id = \"models/stable-diffusion-v2-512x512\"\n",
    "\n",
    "# Use the Euler scheduler here instead\n",
    "# scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id,scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "# pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(0)\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model locally after initial download\n",
    "# pipe.save_pretrained('models/stable-diffusion-v2-512x512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-slugify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nfxOjVrFq-9"
   },
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "from time import time\n",
    "\n",
    "# prompt = \"low angle 50mm photograph of a majestic bacon-cheesehamburger composed of grilled beef patties and fresh salad and tomato and secret sauce and melted american cheese and sesame seed buns, 4k award winning food photography, trending on artstation\"\n",
    "# prompt = \"plateau de fromages frais et affinés 999€\"\n",
    "\n",
    "# prompt = \"La religieuse est composée de deux choux posés l'un sur l'autre, dont le chou supérieur, qui est censé représenter la tête, est deux fois plus petit.Les choux sont recouverts de fondant du même parfum que la crème pâtissière, et une crème au beurre généralement parfumée au café ou à la vanille permet de tenir la tête.\"\n",
    "\n",
    "# prompt = \"Religieuse is a French pastry, 999€\"\n",
    "\n",
    "prompt = \"top view picture, of a michelin star restaurant dish, award winning food photography, 4k food picture, french signature dish, silver cutlery on each side of the plate, ornated porcelain plate with floral patterns and gilded meandros, crystal drinking glass with red wine, everything is resting on a marble table, fresh flower arrangement in an ornate vase, ming vase holding flowers\"\n",
    "\n",
    "\n",
    "prompt = \"45 degree angle picture, of a cheeseburger, of michelin star dish, of silver cutlery, 50mm lens food photography, vibrant colors, by Caravaggio\"\n",
    "neg_prompt = \"blurry, out of focus, cropped, too crowded, tarnished look, deformed\"\n",
    "\n",
    "set_guidance_scale = 7.5\n",
    "\n",
    "def txt2img(prompt, neg_prompt, n_iterations, display_image, in_num_inference_steps):\n",
    "    \n",
    "    seed_generator = torch.Generator('cuda').manual_seed(42)\n",
    "    image = None\n",
    "    for i in range(n_iterations):\n",
    "        with autocast('cuda'):\n",
    "          image = pipe(prompt, negative_prompt=neg_prompt, height=512, width=512,generator=seed_generator, guidance_scale = set_guidance_scale, num_inference_steps = in_num_inference_steps).images[0]\n",
    "          image.save(f\"images/{slugify(prompt)[:100]}_{i}_{time()}.png\")\n",
    "        if display_image:\n",
    "            display(image)\n",
    "\n",
    "    # return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GG_aywiYDoRv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = txt2img(prompt,neg_prompt, 10, True, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
